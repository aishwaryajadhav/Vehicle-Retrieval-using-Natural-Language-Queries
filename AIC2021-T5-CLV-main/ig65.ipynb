{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bef668e-87fb-4057-9ff9-33f8b83a7bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import config\n",
    "import importlib\n",
    "from torchvision.transforms import Compose\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "from transforms import ToTensor, Resize, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da00a0b1-fc29-4d77-b2da-4ad917cbe610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from '/home/ubuntu/efs/code/11775Proj/AIC2021-T5-CLV-main/config.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(datasets)\n",
    "importlib.reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fd7e8ca-2ccc-48c9-8728-4c2c8c7b9572",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "        ToTensor(),\n",
    "        Rearrange(\"t h w c -> c t h w\"),\n",
    "        Resize((224, 224)),\n",
    "        Normalize(mean=[0.43216, 0.394666, 0.37645], std=[0.22803, 0.22145, 0.216989]),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49d1ea78-d002-4a83-93e8-7d83f49b13fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207\n",
      "data load\n"
     ]
    }
   ],
   "source": [
    "cfg = config.get_default_config()\n",
    "train_data=datasets.CityFlowNLVideoDataset(cfg.DATA, json_path = cfg.DATA.TRAIN_JSON_PATH, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab87521a-4c9e-49b9-8e7d-4e4c592b6f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset=train_data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c9386f4-56ff-4942-8ce5-ee99b059cc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10101010101010\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, batch in enumerate(trainloader):\n",
    "    print(batch_idx)\n",
    "    # print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55f3e432-43eb-44c3-a190-52b1c0b00eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4b206ab-30df-464c-9212-c452a8e0875a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 33, 224, 224])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96dba290-794a-433c-943b-4d7f349f7830",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frames = batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82ade891-1678-4fe9-92fe-f0488f60b617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A white cargo truck keeps straight down the road.',)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93e319e7-e2b7-4d9b-a1bc-f61a980def6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.video_encoder import r2plus1d_34_32_ig65m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0397314d-8bd6-47dd-95e7-ed7e2574edcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = r2plus1d_34_32_ig65m(359, pretrained=True, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4806f6-e585-4914-ae0f-d572690ecbf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593ac4a7-19b8-435b-8f6c-f710586294dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "op = model(video_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0680801-0eac-4940-80c5-177dfa76cced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75ca8bc-278c-455c-95e3-9c7aee99ed4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9bf910-b664-4632-93cd-e22292439438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2d591a-b1fa-45c5-8b2f-1e7136a5d430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f77981-75f4-4595-8235-f3592ba935c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ad9e11c5-a346-4b8e-9fdd-412701956166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "vpath = \"/home/ubuntu/efs/data/aicity/validation_tracks/fff8a39d-bb90-4a1f-8a8a-7761e1a78913.mp4\"\n",
    "video = cv2.VideoCapture(vpath)\n",
    "amount_of_frames = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, amount_of_frames-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5bb12fac-63cd-4620-9f17-1963245c8336",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, frames = video.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "11b91bd5-b21e-45a2-9e52-b9b0697120b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1920, 2560, 3)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2c166e79-cfc4-4a64-8ecb-275ce31d1001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.0\n"
     ]
    }
   ],
   "source": [
    "print(amount_of_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "72e9911f-81e5-446a-af82-5294dd9d5098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_video\n",
    "video, _, _ = read_video(vpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "37894f8f-f801-4591-8093-8e374dfc167d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"compute_indices_weights_linear\" not implemented for 'Byte'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4332/1315132231.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/efs/envs/image/lib/python3.9/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/efs/code/11775Proj/AIC2021-T5-CLV-main/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, video)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         return nn.functional.interpolate(video, size=size, scale_factor=scale,\n\u001b[0m\u001b[1;32m     29\u001b[0m                                          mode=self.mode, align_corners=False)\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/efs/envs/image/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor)\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"bilinear\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3730\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0malign_corners\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3731\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_bilinear2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3732\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"trilinear\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3733\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0malign_corners\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"compute_indices_weights_linear\" not implemented for 'Byte'"
     ]
    }
   ],
   "source": [
    "transform(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c3b999c4-72c9-40ce-bdc4-e6c3d8880b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = video.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "30f6fc2b-c61b-4c5c-bd50-85df3685dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transforms import ToTensor, Resize, Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0c8f00-23ec-4ec9-910f-642af6cca65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8116b3a5-f2b8-4de8-be25-e0df463e22a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
